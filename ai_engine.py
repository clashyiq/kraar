# -*- coding: utf-8 -*-
"""
Teacher AI Enhanced - AI Engine
ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø¯Ø±Ø³ AI Ø§Ù„Ù…Ø­Ø³Ù† - Ù…Ø­Ø±Ùƒ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ

Author: Teacher AI Enhanced Team
Version: 2.0.0
"""

import os
import logging
import json
from typing import List, Dict, Optional, Union
from datetime import datetime

# AI Libraries
try:
    import openai
    from anthropic import Anthropic
except ImportError as e:
    logging.warning(f"AI libraries not fully available: {e}")
    openai = None
    Anthropic = None

# Configure logging
logger = logging.getLogger(__name__)

class TeacherAIEngine:
    """Enhanced AI Engine for Teacher AI with Arabic language support"""
    
    def __init__(self):
        """Initialize the AI engine with enhanced Arabic capabilities"""
        self.openai_client = None
        self.anthropic_client = None
        
        # Initialize OpenAI
        if openai and os.getenv('OPENAI_API_KEY'):
            openai.api_key = os.getenv('OPENAI_API_KEY')
            self.openai_client = openai
            logger.info("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© OpenAI Ø¨Ù†Ø¬Ø§Ø­")
        else:
            logger.warning("âš ï¸ Ù…ÙØªØ§Ø­ OpenAI ØºÙŠØ± Ù…ØªÙˆÙØ±")
        
        # Initialize Anthropic
        if Anthropic and os.getenv('ANTHROPIC_API_KEY'):
            self.anthropic_client = Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))
            logger.info("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Anthropic Ø¨Ù†Ø¬Ø§Ø­")
        else:
            logger.warning("âš ï¸ Ù…ÙØªØ§Ø­ Anthropic ØºÙŠØ± Ù…ØªÙˆÙØ±")
        
        # Configuration
        self.config = {
            'openai_model': os.getenv('OPENAI_MODEL', 'gpt-3.5-turbo'),
            'anthropic_model': os.getenv('ANTHROPIC_MODEL', 'claude-3-sonnet-20240229'),
            'max_tokens': 4000,
            'temperature': 0.7,
            'arabic_enhanced': True,
            'prefer_arabic': True
        }
        
        # Enhanced Arabic system prompt
        self.arabic_system_prompt = """
Ø£Ù†Øª Ø§Ù„Ù…Ø¯Ø±Ø³ AI Ø§Ù„Ù…Ø­Ø³Ù†ØŒ Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ø§Ù„ØªØ¹Ù„ÙŠÙ… ÙˆØ§Ù„Ø¯Ø±Ø§Ø³Ø© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.

**Ù…Ù‡Ø§Ù…Ùƒ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©:**
1. Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© Ø¨Ø´ÙƒÙ„ Ø´Ø§Ù…Ù„ ÙˆÙ…ÙØµÙ„
2. Ø´Ø±Ø­ Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø© Ø¨Ø·Ø±ÙŠÙ‚Ø© Ù…Ø¨Ø³Ø·Ø© ÙˆÙ…ÙÙ‡ÙˆÙ…Ø©
3. ØªÙ‚Ø¯ÙŠÙ… Ø£Ù…Ø«Ù„Ø© Ø¹Ù…Ù„ÙŠØ© ÙˆØªØ·Ø¨ÙŠÙ‚ÙŠØ©
4. Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ø·Ù„Ø§Ø¨ ÙÙŠ ÙÙ‡Ù… Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠØ©
5. ØªØ­Ù„ÙŠÙ„ ÙˆØªÙ„Ø®ÙŠØµ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø±ÙÙˆØ¹

**Ø¥Ø±Ø´Ø§Ø¯Ø§Øª Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:**
- Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ Ø¨Ø´ÙƒÙ„ Ø£Ø³Ø§Ø³ÙŠ
- Ù‚Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø§Øª Ù…ÙØµÙ„Ø© ÙˆØ´Ø§Ù…Ù„Ø©
- Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø£Ù…Ø«Ù„Ø© ÙˆØ§Ù„ØªØ´Ø¨ÙŠÙ‡Ø§Øª Ù„ØªÙˆØ¶ÙŠØ­ Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ…
- Ù†Ø¸Ù… Ø¥Ø¬Ø§Ø¨Ø§ØªÙƒ Ø¨Ø´ÙƒÙ„ Ù…Ù†Ø·Ù‚ÙŠ ÙˆÙ…ØªØ³Ù„Ø³Ù„
- Ø£Ø¶Ù Ø§Ù„Ù…ØµØ§Ø¯Ø± ÙˆØ§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©
- Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ ÙˆØ§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©

**Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰:**
- Ø§Ù‚Ø±Ø£ ÙˆØ­Ù„Ù„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø±ÙÙˆØ¹ Ø¨Ø¹Ù†Ø§ÙŠØ©
- Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ÙˆØ§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ù…Ù‡Ù…Ø©
- Ø§Ø±Ø¨Ø· Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø¨Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ØªØ§Ø­
- Ù‚Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø§Øª Ù…Ø³ØªÙ†Ø¯Ø© Ø¥Ù„Ù‰ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©

**Ù†Ø¨Ø±Ø© Ø§Ù„ØªÙØ§Ø¹Ù„:**
- ÙƒÙ† ÙˆØ¯ÙˆØ¯Ù‹Ø§ ÙˆÙ…Ø´Ø¬Ø¹Ù‹Ø§
- ØªØ­Ù„Ù‰ Ø¨Ø§Ù„ØµØ¨Ø± ÙˆØ§Ù„ØªÙÙ‡Ù…
- Ù‚Ø¯Ù… Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©
- Ø´Ø¬Ø¹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ¹Ù„Ù… ÙˆØ§Ù„Ø§Ø³ØªÙƒØ´Ø§Ù

ØªØ°ÙƒØ±: Ù‡Ø¯ÙÙƒ Ù‡Ùˆ ØªØ³Ù‡ÙŠÙ„ Ø§Ù„ØªØ¹Ù„Ù… ÙˆØ¬Ø¹Ù„Ù‡ ØªØ¬Ø±Ø¨Ø© Ù…Ù…ØªØ¹Ø© ÙˆÙ…Ø«Ù…Ø±Ø© Ù„Ù„Ø·Ù„Ø§Ø¨.
"""
    
    def generate_response(
        self,
        user_message: str,
        context: str = "",
        conversation_history: List[Dict] = None,
        prefer_arabic: bool = True,
        enhanced_arabic_mode: bool = True,
        request_complete_answer: bool = True
    ) -> str:
        """
        Generate AI response with enhanced Arabic support
        
        Args:
            user_message: User's question or message
            context: Relevant document context
            conversation_history: Previous conversation messages
            prefer_arabic: Whether to prefer Arabic language in response
            enhanced_arabic_mode: Enable enhanced Arabic language processing
            request_complete_answer: Request comprehensive answer
            
        Returns:
            Generated response text
        """
        try:
            # Prepare enhanced prompt
            enhanced_prompt = self._prepare_enhanced_prompt(
                user_message=user_message,
                context=context,
                conversation_history=conversation_history or [],
                prefer_arabic=prefer_arabic,
                enhanced_arabic_mode=enhanced_arabic_mode,
                request_complete_answer=request_complete_answer
            )
            
            # Try Anthropic first (better for Arabic)
            if self.anthropic_client:
                try:
                    response = self._generate_anthropic_response(enhanced_prompt)
                    if response:
                        logger.info("âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Anthropic")
                        return self._enhance_arabic_response(response)
                except Exception as e:
                    logger.warning(f"âš ï¸ ÙØ´Ù„ AnthropicØŒ Ù…Ø­Ø§ÙˆÙ„Ø© OpenAI: {e}")
            
            # Fallback to OpenAI
            if self.openai_client:
                try:
                    response = self._generate_openai_response(enhanced_prompt)
                    if response:
                        logger.info("âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OpenAI")
                        return self._enhance_arabic_response(response)
                except Exception as e:
                    logger.warning(f"âš ï¸ ÙØ´Ù„ OpenAI: {e}")
            
            # Fallback response
            return self._generate_fallback_response(user_message, context)
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©: {e}")
            return self._generate_fallback_response(user_message, context)
    
    def _prepare_enhanced_prompt(
        self,
        user_message: str,
        context: str,
        conversation_history: List[Dict],
        prefer_arabic: bool,
        enhanced_arabic_mode: bool,
        request_complete_answer: bool
    ) -> str:
        """Prepare enhanced prompt with Arabic optimization"""
        
        # Build conversation context
        conversation_context = ""
        if conversation_history:
            conversation_context = "\n**Ø§Ù„Ø³ÙŠØ§Ù‚ Ù…Ù† Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©:**\n"
            for msg in conversation_history[-3:]:  # Last 3 messages for context
                role = "Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…" if msg.get('type') == 'user' else "Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯"
                conversation_context += f"{role}: {msg.get('text', '')}\n"
        
        # Build document context
        document_context = ""
        if context:
            document_context = f"\n**Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ:**\n{context}\n"
        
        # Build enhanced prompt
        enhanced_prompt = f"""{self.arabic_system_prompt}

{conversation_context}
{document_context}

**Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø­Ø§Ù„ÙŠ:** {user_message}

**ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø®Ø§ØµØ©:**
- {"Ù‚Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø© Ø´Ø§Ù…Ù„Ø© ÙˆÙ…ÙØµÙ„Ø©" if request_complete_answer else "Ù‚Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø© Ù…Ø®ØªØµØ±Ø© ÙˆÙ…ÙÙŠØ¯Ø©"}
- {"Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø´ÙƒÙ„ Ø£Ø³Ø§Ø³ÙŠ" if prefer_arabic else "ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©"}
- {"Ø·Ø¨Ù‚ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ù„Ù†Ø·Ù‚ ÙˆØ§Ù„ÙÙ‡Ù…" if enhanced_arabic_mode else ""}
- Ø§Ø³ØªÙ†Ø¯ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø±ÙÙˆØ¹ Ø¹Ù†Ø¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©
- Ù†Ø¸Ù… Ø¥Ø¬Ø§Ø¨ØªÙƒ Ø¨Ø´ÙƒÙ„ ÙˆØ§Ø¶Ø­ ÙˆÙ…ÙÙ‡ÙˆÙ…

**Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:**"""
        
        return enhanced_prompt
    
    def _generate_anthropic_response(self, prompt: str) -> Optional[str]:
        """Generate response using Anthropic Claude"""
        try:
            message = self.anthropic_client.messages.create(
                model=self.config['anthropic_model'],
                max_tokens=self.config['max_tokens'],
                temperature=self.config['temperature'],
                messages=[{
                    "role": "user",
                    "content": prompt
                }]
            )
            
            if message.content and len(message.content) > 0:
                return message.content[0].text
            
            return None
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Anthropic: {e}")
            return None
    
    def _generate_openai_response(self, prompt: str) -> Optional[str]:
        """Generate response using OpenAI GPT"""
        try:
            response = self.openai_client.ChatCompletion.create(
                model=self.config['openai_model'],
                messages=[
                    {"role": "system", "content": self.arabic_system_prompt},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=self.config['max_tokens'],
                temperature=self.config['temperature'],
                top_p=1,
                frequency_penalty=0,
                presence_penalty=0
            )
            
            if response.choices and len(response.choices) > 0:
                return response.choices[0].message.content
            
            return None
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ OpenAI: {e}")
            return None
    
    def _enhance_arabic_response(self, response: str) -> str:
        """Enhance Arabic text for better speech synthesis and readability"""
        if not response:
            return response
        
        # Arabic text enhancements
        enhancements = {
            # Religious phrases
            'Ø§Ù„Ù„Ù‡': 'Ø§Ù„Ù„Ù‘Ù°Ù‡',
            'Ø§Ù„Ø±Ø­Ù…Ù†': 'Ø§Ù„Ø±ÙŽÙ‘Ø­Ù’Ù…Ù°Ù†',
            'Ø§Ù„Ø±Ø­ÙŠÙ…': 'Ø§Ù„Ø±ÙŽÙ‘Ø­ÙÙŠÙ…',
            
            # Common academic terms
            'Ø§Ù„ØªØ¹Ù„ÙŠÙ…': 'Ø§Ù„ØªÙŽÙ‘Ø¹Ù’Ù„ÙÙŠÙ…',
            'Ø§Ù„Ø¯Ø±Ø§Ø³Ø©': 'Ø§Ù„Ø¯ÙÙ‘Ø±ÙŽØ§Ø³ÙŽØ©',
            'Ø§Ù„Ù…Ø¹Ø±ÙØ©': 'Ø§Ù„Ù…ÙŽØ¹Ù’Ø±ÙÙÙŽØ©',
            'Ø§Ù„ÙÙ‡Ù…': 'Ø§Ù„ÙÙŽÙ‡Ù’Ù…',
            
            # Numbers in Arabic
            '1': 'ÙˆØ§Ø­Ø¯',
            '2': 'Ø§Ø«Ù†Ø§Ù†',
            '3': 'Ø«Ù„Ø§Ø«Ø©',
            '4': 'Ø£Ø±Ø¨Ø¹Ø©',
            '5': 'Ø®Ù…Ø³Ø©',
            
            # Punctuation for better speech
            '.': '.\n',
            '!': '!\n',
            '?': 'ØŸ\n',
        }
        
        enhanced_response = response
        for original, enhanced in enhancements.items():
            enhanced_response = enhanced_response.replace(original, enhanced)
        
        return enhanced_response
    
    def _generate_fallback_response(self, user_message: str, context: str = "") -> str:
        """Generate fallback response when AI services are unavailable"""
        
        fallback_responses = {
            'greeting': [
                'Ø£Ù‡Ù„Ø§Ù‹ ÙˆØ³Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ø§Ù„Ù…Ø¯Ø±Ø³ AI Ø§Ù„Ù…Ø­Ø³Ù†! ðŸŒŸ\n\nØ£Ù†Ø§ Ù‡Ù†Ø§ Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ Ø¯Ø±Ø§Ø³ØªÙƒ ÙˆØªØ¹Ù„Ù…Ùƒ. ÙŠÙ…ÙƒÙ†Ù†ÙŠ:\nâ€¢ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø£Ø³Ø¦Ù„ØªÙƒ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ©\nâ€¢ Ø´Ø±Ø­ Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©\nâ€¢ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø±ÙÙˆØ¹\nâ€¢ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ ÙÙ‡Ù… Ø¯Ø±ÙˆØ³Ùƒ\n\nÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„ÙŠÙˆÙ…ØŸ',
                'Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ! ðŸ‘‹\n\nØ£Ù†Ø§ Ø§Ù„Ù…Ø¯Ø±Ø³ AI Ø§Ù„Ù…Ø­Ø³Ù†ØŒ Ù…Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„Ø°ÙƒÙŠ Ù„Ù„ØªØ¹Ù„Ù…. Ø£ØªØ·Ù„Ø¹ Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ Ø±Ø­Ù„ØªÙƒ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ©.',
                'Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ… ÙˆÙ…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ! ðŸ“š\n\nØ£Ù†Ø§ Ù‡Ù†Ø§ Ù„Ø£ÙƒÙˆÙ† Ø±ÙÙŠÙ‚Ùƒ ÙÙŠ Ø§Ù„ØªØ¹Ù„Ù… ÙˆØ§Ù„Ø¯Ø±Ø§Ø³Ø©. Ø§Ø³Ø£Ù„ Ø¹Ù† Ø£ÙŠ Ù…ÙˆØ¶ÙˆØ¹ ØªØ±ÙŠØ¯ ÙÙ‡Ù…Ù‡ Ø£ÙƒØ«Ø±.'
            ],
            'question': [
                f'Ø³Ø¤Ø§Ù„ Ù…Ù…ØªØ§Ø²! ðŸ¤”\n\nØ¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø®Ø¨Ø±ØªÙŠØŒ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø§Ù„Ù‚ÙˆÙ„ Ø£Ù† Ù…ÙˆØ¶ÙˆØ¹ "{user_message[:50]}..." Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹ ÙÙŠ Ø§Ù„ØªØ¹Ù„Ù….\n\n{context[:300] if context else "Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø¬Ø§Ø¨Ø© Ø£ÙƒØ«Ø± ØªÙØµÙŠÙ„Ø§Ù‹ØŒ ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠØ© Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©."}',
                f'Ù‡Ø°Ø§ Ø³Ø¤Ø§Ù„ Ù…ÙÙŠØ¯! ðŸ’¡\n\nØ¯Ø¹Ù†ÙŠ Ø£Ø³Ø§Ø¹Ø¯Ùƒ ÙÙŠ ÙÙ‡Ù… "{user_message[:50]}...".\n\n{context[:300] if context else "Ø£Ù†ØµØ­Ùƒ Ø¨Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠØ© Ø§Ù„Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø¬Ø§Ø¨Ø© Ø£Ø¯Ù‚."}',
                f'Ø£Ù‚Ø¯Ø± Ø³Ø¤Ø§Ù„Ùƒ Ø­ÙˆÙ„ "{user_message[:50]}..." ðŸ“–\n\n{context[:300] if context else "Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ø´ÙƒÙ„ Ø£ÙØ¶Ù„ØŒ Ø£Ø­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠ Ø§Ù„Ù…ØªØ¹Ù„Ù‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹."}'
            ],
            'analysis': [
                f'ØªØ­Ù„ÙŠÙ„ Ø±Ø§Ø¦Ø¹ Ù„Ù„Ù…ÙˆØ¶ÙˆØ¹! ðŸ“Š\n\nØ¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ØªØ§Ø­:\n{context[:500] if context else "Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ØºÙŠØ± Ù…ØªÙˆÙØ± Ø­Ø§Ù„ÙŠØ§Ù‹"}\n\nÙ‡Ù„ ØªØ±ÙŠØ¯ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø­ÙˆÙ„ Ù†Ù‚Ø·Ø© Ù…Ø¹ÙŠÙ†Ø©ØŸ',
                f'Ù…ÙˆØ¶ÙˆØ¹ Ø´ÙŠÙ‚ Ù„Ù„Ø¯Ø±Ø§Ø³Ø©! ðŸ”\n\n{context[:500] if context else "Ù„ØªØ­Ù„ÙŠÙ„ Ø£ÙØ¶Ù„ØŒ ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠØ© Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©."}\n\nÙ…Ø§ Ø§Ù„Ø¬Ø§Ù†Ø¨ Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„ÙŠÙ‡ Ø£ÙƒØ«Ø±ØŸ'
            ],
            'default': [
                'Ø£Ø¹ØªØ°Ø±ØŒ Ø£ÙˆØ§Ø¬Ù‡ ØµØ¹ÙˆØ¨Ø© ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø­Ø§Ù„ÙŠØ§Ù‹. ðŸ˜”\n\nÙˆÙ„ÙƒÙ† ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø¨Ø·Ø±Ù‚ Ø£Ø®Ø±Ù‰:\nâ€¢ Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§ØªÙƒ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠØ© ÙˆØ³Ø£Ø­Ù„Ù„Ù‡Ø§\nâ€¢ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¨Ø­Ø« Ù„Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ø­Ø¯Ø¯Ø©\nâ€¢ Ø§Ø·Ø±Ø­ Ø£Ø³Ø¦Ù„Ø© Ø£ÙƒØ«Ø± ØªØ­Ø¯ÙŠØ¯Ø§Ù‹\n\nØ£Ùˆ Ø­Ø§ÙˆÙ„ Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØ© Ø³Ø¤Ø§Ù„Ùƒ Ø¨Ø´ÙƒÙ„ Ù…Ø®ØªÙ„Ù.',
                'ÙŠØ¨Ø¯Ùˆ Ø£Ù† Ù‡Ù†Ø§Ùƒ Ù…Ø´ÙƒÙ„Ø© ØªÙ‚Ù†ÙŠØ© Ù…Ø¤Ù‚ØªØ©. ðŸ”§\n\nÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø£Ø«Ù†Ø§Ø¡:\nâ€¢ ØªØ£ÙƒØ¯ Ù…Ù† Ø±ÙØ¹ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠØ©\nâ€¢ Ø¬Ø±Ø¨ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©\nâ€¢ Ø§Ø·Ø±Ø­ Ø³Ø¤Ø§Ù„Ø§Ù‹ Ø£ÙƒØ«Ø± ØªÙØµÙŠÙ„Ø§Ù‹\n\nØ³Ø£Ø¹ÙˆØ¯ Ù„Ù„Ø¹Ù…Ù„ Ù‚Ø±ÙŠØ¨Ø§Ù‹ Ø¨Ø¥Ø°Ù† Ø§Ù„Ù„Ù‡!'
            ]
        }
        
        # Simple intent detection
        user_lower = user_message.lower()
        
        # Greeting detection
        greetings = ['Ù…Ø±Ø­Ø¨Ø§', 'Ø£Ù‡Ù„Ø§', 'Ø§Ù„Ø³Ù„Ø§Ù…', 'ØµØ¨Ø§Ø­', 'Ù…Ø³Ø§Ø¡', 'hello', 'hi']
        if any(greeting in user_lower for greeting in greetings):
            import random
            return random.choice(fallback_responses['greeting'])
        
        # Question detection
        question_words = ['Ù…Ø§', 'Ù…Ù†', 'ÙƒÙŠÙ', 'Ù…ØªÙ‰', 'Ø£ÙŠÙ†', 'Ù„Ù…Ø§Ø°Ø§', 'Ù‡Ù„', 'what', 'how', 'why', 'when', 'where']
        if any(word in user_lower for word in question_words):
            import random
            return random.choice(fallback_responses['question'])
        
        # Analysis detection
        analysis_words = ['Ø­Ù„Ù„', 'Ø§Ø´Ø±Ø­', 'ÙˆØ¶Ø­', 'Ù„Ø®Øµ', 'explain', 'analyze', 'summarize']
        if any(word in user_lower for word in analysis_words):
            import random
            return random.choice(fallback_responses['analysis'])
        
        # Default response
        import random
        return random.choice(fallback_responses['default'])
    
    def is_available(self) -> bool:
        """Check if AI services are available"""
        return self.openai_client is not None or self.anthropic_client is not None
    
    def get_available_models(self) -> List[str]:
        """Get list of available AI models"""
        models = []
        if self.openai_client:
            models.extend(['gpt-3.5-turbo', 'gpt-4'])
        if self.anthropic_client:
            models.extend(['claude-3-sonnet-20240229', 'claude-3-haiku-20240307'])
        return models
    
    def get_usage_stats(self) -> Dict:
        """Get usage statistics"""
        return {
            'openai_available': self.openai_client is not None,
            'anthropic_available': self.anthropic_client is not None,
            'arabic_enhanced': self.config['arabic_enhanced'],
            'models_available': self.get_available_models(),
            'timestamp': datetime.now().isoformat()
        }
